{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo\n",
    "* Preprocess the data properly\n",
    "    - remove frames that has both left hand and right hand as nan\n",
    "    - Identify the dominant hand NB:(In the current competition, I suspect that both hands would be used in making words or signs)\n",
    "    - Normalization of the data\n",
    "    - Pad shorter sequence with 0, and mean pool longer sequence so each video can be of the same frame length. : DONE \n",
    "    - Fill NaN values with 0\n",
    "\n",
    "* How can I map some important signs of the body like\n",
    "    - lips \n",
    "    - nose \n",
    "    - pose\n",
    "\n",
    "* Building of the model I was think of using a GRU model something similar to https://www.kaggle.com/code/nghihuynh/gislr-inference-transformer \n",
    "    - Transformer Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import plotly.express as px \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHAND = np.arange(468, 489).tolist() # 21\n",
    "RHAND = np.arange(522, 543).tolist() # 21\n",
    "POSE  = np.arange(489, 522).tolist() # 33\n",
    "FACE  = np.arange(0,468).tolist()    #468\n",
    "\n",
    "NOSE=[\n",
    "    1,2,98,327\n",
    "]\n",
    "LNOSE = [98]\n",
    "RNOSE = [327]\n",
    "LIP = [ 0, \n",
    "    61, 185, 40, 39, 37, 267, 269, 270, 409,\n",
    "    291, 146, 91, 181, 84, 17, 314, 405, 321, 375,\n",
    "    78, 191, 80, 81, 82, 13, 312, 311, 310, 415,\n",
    "    95, 88, 178, 87, 14, 317, 402, 318, 324, 308,\n",
    "]\n",
    "LLIP = [84,181,91,146,61,185,40,39,37,87,178,88,95,78,191,80,81,82]\n",
    "RLIP = [314,405,321,375,291,409,270,269,267,317,402,318,324,308,415,310,311,312]\n",
    "\n",
    "POSE = [500, 502, 504, 501, 503, 505, 512, 513]\n",
    "LPOSE = [513,505,503,501]\n",
    "RPOSE = [512,504,502,500]\n",
    "\n",
    "REYE = [\n",
    "    33, 7, 163, 144, 145, 153, 154, 155, 133,\n",
    "    246, 161, 160, 159, 158, 157, 173,\n",
    "]\n",
    "LEYE = [\n",
    "    263, 249, 390, 373, 374, 380, 381, 382, 362,\n",
    "    466, 388, 387, 386, 385, 384, 398,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_parquet('/Users/dimeji/Documents/Projects/Sign Language/sign_data/asl-signs/train_landmark_files/2044/635217.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'sign_data/asl-signs'\n",
    "train = pd.read_csv(f'{BASE_DIR}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign  \n",
       "0       1000035562    blow  \n",
       "1       1000106739    wait  \n",
       "2        100015657   cloud  \n",
       "3       1000210073    bird  \n",
       "4       1000240708    owie  \n",
       "...            ...     ...  \n",
       "94472    999786174   white  \n",
       "94473    999799849    have  \n",
       "94474    999833418  flower  \n",
       "94475    999895257    room  \n",
       "94476    999962374   happy  \n",
       "\n",
       "[94477 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get complete file path to file\n",
    "def get_file_path(path):\n",
    "    return f'sign_data/asl-signs/{path}'\n",
    "\n",
    "train['file_path'] = train['path'].apply(get_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/26734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/28656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/16069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/25571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/62590...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94472</th>\n",
       "      <td>train_landmark_files/53618/999786174.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>999786174</td>\n",
       "      <td>white</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/53618...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94473</th>\n",
       "      <td>train_landmark_files/26734/999799849.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>999799849</td>\n",
       "      <td>have</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/26734...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94474</th>\n",
       "      <td>train_landmark_files/25571/999833418.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>999833418</td>\n",
       "      <td>flower</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/25571...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94475</th>\n",
       "      <td>train_landmark_files/29302/999895257.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>999895257</td>\n",
       "      <td>room</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/29302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94476</th>\n",
       "      <td>train_landmark_files/36257/999962374.parquet</td>\n",
       "      <td>36257</td>\n",
       "      <td>999962374</td>\n",
       "      <td>happy</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/36257...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94477 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "0      train_landmark_files/26734/1000035562.parquet           26734   \n",
       "1      train_landmark_files/28656/1000106739.parquet           28656   \n",
       "2       train_landmark_files/16069/100015657.parquet           16069   \n",
       "3      train_landmark_files/25571/1000210073.parquet           25571   \n",
       "4      train_landmark_files/62590/1000240708.parquet           62590   \n",
       "...                                              ...             ...   \n",
       "94472   train_landmark_files/53618/999786174.parquet           53618   \n",
       "94473   train_landmark_files/26734/999799849.parquet           26734   \n",
       "94474   train_landmark_files/25571/999833418.parquet           25571   \n",
       "94475   train_landmark_files/29302/999895257.parquet           29302   \n",
       "94476   train_landmark_files/36257/999962374.parquet           36257   \n",
       "\n",
       "       sequence_id    sign                                          file_path  \n",
       "0       1000035562    blow  sign_data/asl-signs/train_landmark_files/26734...  \n",
       "1       1000106739    wait  sign_data/asl-signs/train_landmark_files/28656...  \n",
       "2        100015657   cloud  sign_data/asl-signs/train_landmark_files/16069...  \n",
       "3       1000210073    bird  sign_data/asl-signs/train_landmark_files/25571...  \n",
       "4       1000240708    owie  sign_data/asl-signs/train_landmark_files/62590...  \n",
       "...            ...     ...                                                ...  \n",
       "94472    999786174   white  sign_data/asl-signs/train_landmark_files/53618...  \n",
       "94473    999799849    have  sign_data/asl-signs/train_landmark_files/26734...  \n",
       "94474    999833418  flower  sign_data/asl-signs/train_landmark_files/25571...  \n",
       "94475    999895257    room  sign_data/asl-signs/train_landmark_files/29302...  \n",
       "94476    999962374   happy  sign_data/asl-signs/train_landmark_files/36257...  \n",
       "\n",
       "[94477 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinal Encode Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('sign_data/asl-signs/sign_to_prediction_index_map.json') as f: \n",
    "    sign_map = json.load(f)\n",
    "\n",
    "signs = list(sign_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TV', 'after', 'airplane', 'all', 'alligator']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_sign_code(sign: str):\n",
    "    return sign_map[sign]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['sign_code'] = train['sign'].apply(mapping_sign_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instantiate the encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit the encoder and transform the 'sign' column\n",
    "train['sign_code'] = le.fit_transform(train['sign'])\n",
    "\n",
    "# Create dictionaries for mapping\n",
    "SIGN2ORD = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "ORD2SIGN = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "      <th>file_path</th>\n",
       "      <th>sign_code</th>\n",
       "      <th>sign_ord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_landmark_files/26734/1000035562.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000035562</td>\n",
       "      <td>blow</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/26734...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_landmark_files/28656/1000106739.parquet</td>\n",
       "      <td>28656</td>\n",
       "      <td>1000106739</td>\n",
       "      <td>wait</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/28656...</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_landmark_files/16069/100015657.parquet</td>\n",
       "      <td>16069</td>\n",
       "      <td>100015657</td>\n",
       "      <td>cloud</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/16069...</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_landmark_files/25571/1000210073.parquet</td>\n",
       "      <td>25571</td>\n",
       "      <td>1000210073</td>\n",
       "      <td>bird</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/25571...</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_landmark_files/62590/1000240708.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1000240708</td>\n",
       "      <td>owie</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/62590...</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_landmark_files/26734/1000241583.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000241583</td>\n",
       "      <td>duck</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/26734...</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train_landmark_files/26734/1000255522.parquet</td>\n",
       "      <td>26734</td>\n",
       "      <td>1000255522</td>\n",
       "      <td>minemy</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/26734...</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_landmark_files/32319/1000278229.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>1000278229</td>\n",
       "      <td>lips</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/32319...</td>\n",
       "      <td>134</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_landmark_files/37055/100035691.parquet</td>\n",
       "      <td>37055</td>\n",
       "      <td>100035691</td>\n",
       "      <td>flower</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/37055...</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train_landmark_files/29302/100039661.parquet</td>\n",
       "      <td>29302</td>\n",
       "      <td>100039661</td>\n",
       "      <td>time</td>\n",
       "      <td>sign_data/asl-signs/train_landmark_files/29302...</td>\n",
       "      <td>220</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            path  participant_id  sequence_id  \\\n",
       "0  train_landmark_files/26734/1000035562.parquet           26734   1000035562   \n",
       "1  train_landmark_files/28656/1000106739.parquet           28656   1000106739   \n",
       "2   train_landmark_files/16069/100015657.parquet           16069    100015657   \n",
       "3  train_landmark_files/25571/1000210073.parquet           25571   1000210073   \n",
       "4  train_landmark_files/62590/1000240708.parquet           62590   1000240708   \n",
       "5  train_landmark_files/26734/1000241583.parquet           26734   1000241583   \n",
       "6  train_landmark_files/26734/1000255522.parquet           26734   1000255522   \n",
       "7  train_landmark_files/32319/1000278229.parquet           32319   1000278229   \n",
       "8   train_landmark_files/37055/100035691.parquet           37055    100035691   \n",
       "9   train_landmark_files/29302/100039661.parquet           29302    100039661   \n",
       "\n",
       "     sign                                          file_path  sign_code  \\\n",
       "0    blow  sign_data/asl-signs/train_landmark_files/26734...         25   \n",
       "1    wait  sign_data/asl-signs/train_landmark_files/28656...        232   \n",
       "2   cloud  sign_data/asl-signs/train_landmark_files/16069...         48   \n",
       "3    bird  sign_data/asl-signs/train_landmark_files/25571...         23   \n",
       "4    owie  sign_data/asl-signs/train_landmark_files/62590...        164   \n",
       "5    duck  sign_data/asl-signs/train_landmark_files/26734...         67   \n",
       "6  minemy  sign_data/asl-signs/train_landmark_files/26734...        143   \n",
       "7    lips  sign_data/asl-signs/train_landmark_files/32319...        134   \n",
       "8  flower  sign_data/asl-signs/train_landmark_files/37055...         86   \n",
       "9    time  sign_data/asl-signs/train_landmark_files/29302...        220   \n",
       "\n",
       "   sign_ord  \n",
       "0        25  \n",
       "1       232  \n",
       "2        48  \n",
       "3        23  \n",
       "4       164  \n",
       "5        67  \n",
       "6       143  \n",
       "7       134  \n",
       "8        86  \n",
       "9       220  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 94477 entries, 0 to 94476\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            94477 non-null  object\n",
      " 1   participant_id  94477 non-null  int64 \n",
      " 2   sequence_id     94477 non-null  int64 \n",
      " 3   sign            94477 non-null  object\n",
      " 4   file_path       94477 non-null  object\n",
      " 5   sign_code       94477 non-null  int64 \n",
      " 6   sign_ord        94477 non-null  int16 \n",
      "dtypes: int16(1), int64(3), object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.head(10))\n",
    "display(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROWS_PER_FRAME = 543  \n",
    "\n",
    "def load_relevant_data_subset(pq_path):\n",
    "    data_columns = ['x', 'y', 'z']\n",
    "    data = pd.read_parquet(pq_path, columns=data_columns)\n",
    "    n_frames = int(len(data) / ROWS_PER_FRAME)\n",
    "    data = data.values.reshape(n_frames, ROWS_PER_FRAME, len(data_columns))\n",
    "    return data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 rows\n",
    "df_sample = train.sample(n=1000, random_state=42)\n",
    "\n",
    "# List to hold numpy arrays and labels\n",
    "numpy_arrays = []\n",
    "labels = []\n",
    "\n",
    "# Loop over the sampled DataFrame\n",
    "for _, row in df_sample.iterrows():\n",
    "    # Load the Parquet file and reshape the data\n",
    "    array = load_relevant_data_subset(row['file_path'])\n",
    "    \n",
    "    # Append numpy array to the list\n",
    "    numpy_arrays.append(array)\n",
    "    \n",
    "    # Append label to the list\n",
    "    labels.append(row['sign_ord'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "numpy_arrays = np.array(numpy_arrays)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5144347e-01,  7.5613767e-01,  1.2740776e-06],\n",
       "       [ 2.4153522e-01,  7.2649568e-01, -2.2481397e-02],\n",
       "       [ 2.9584736e-01,  6.6692662e-01, -3.0620238e-02],\n",
       "       [ 3.1995028e-01,  6.1712366e-01, -4.3287758e-02],\n",
       "       [ 3.4872800e-01,  5.7083178e-01, -5.5275746e-02],\n",
       "       [ 2.3215996e-01,  5.8595455e-01,  5.2190065e-02],\n",
       "       [ 2.5217044e-01,  5.2832663e-01,  6.2967956e-02],\n",
       "       [ 2.7134955e-01,  4.8986065e-01,  5.9470192e-02],\n",
       "       [ 2.8328773e-01,  4.5986822e-01,  5.1828388e-02],\n",
       "       [ 1.8974334e-01,  5.7735515e-01,  4.7869675e-02],\n",
       "       [ 2.2290841e-01,  5.2601856e-01,  4.7441982e-02],\n",
       "       [ 2.6852223e-01,  5.0664395e-01,  2.9607691e-02],\n",
       "       [ 3.1005228e-01,  5.0007749e-01,  1.9713828e-02],\n",
       "       [ 1.3828482e-01,  5.7924539e-01,  3.5692640e-02],\n",
       "       [ 1.4157811e-01,  5.1354206e-01,  3.2111593e-02],\n",
       "       [ 1.5732832e-01,  4.7189856e-01,  9.0731150e-03],\n",
       "       [ 1.7816862e-01,  4.4048345e-01, -8.0074295e-03],\n",
       "       [ 8.2876854e-02,  5.9825665e-01,  2.0299291e-02],\n",
       "       [ 5.3168066e-02,  5.4821301e-01,  1.3535727e-02],\n",
       "       [ 3.5480395e-02,  5.1410162e-01,  1.3125769e-03]], dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[0][0][522:542]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.42042042042042\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "for i in range(len(numpy_arrays)): \n",
    "    a += len(numpy_arrays[i])\n",
    "print(a/len(range(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(range(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38382"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[206, 20, 178, 114, 221, 230, 25, 236, 184, 191]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5144347e-01,  7.5613767e-01,  1.2740776e-06],\n",
       "       [ 2.4153522e-01,  7.2649568e-01, -2.2481397e-02],\n",
       "       [ 2.9584736e-01,  6.6692662e-01, -3.0620238e-02],\n",
       "       [ 3.1995028e-01,  6.1712366e-01, -4.3287758e-02],\n",
       "       [ 3.4872800e-01,  5.7083178e-01, -5.5275746e-02],\n",
       "       [ 2.3215996e-01,  5.8595455e-01,  5.2190065e-02],\n",
       "       [ 2.5217044e-01,  5.2832663e-01,  6.2967956e-02],\n",
       "       [ 2.7134955e-01,  4.8986065e-01,  5.9470192e-02],\n",
       "       [ 2.8328773e-01,  4.5986822e-01,  5.1828388e-02],\n",
       "       [ 1.8974334e-01,  5.7735515e-01,  4.7869675e-02],\n",
       "       [ 2.2290841e-01,  5.2601856e-01,  4.7441982e-02],\n",
       "       [ 2.6852223e-01,  5.0664395e-01,  2.9607691e-02],\n",
       "       [ 3.1005228e-01,  5.0007749e-01,  1.9713828e-02],\n",
       "       [ 1.3828482e-01,  5.7924539e-01,  3.5692640e-02],\n",
       "       [ 1.4157811e-01,  5.1354206e-01,  3.2111593e-02],\n",
       "       [ 1.5732832e-01,  4.7189856e-01,  9.0731150e-03],\n",
       "       [ 1.7816862e-01,  4.4048345e-01, -8.0074295e-03],\n",
       "       [ 8.2876854e-02,  5.9825665e-01,  2.0299291e-02],\n",
       "       [ 5.3168066e-02,  5.4821301e-01,  1.3535727e-02],\n",
       "       [ 3.5480395e-02,  5.1410162e-01,  1.3125769e-03]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_arrays[0][0][522:542]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(numpy_arrays)):\n",
    "    frame_mask = np.logical_or(~np.isnan(numpy_arrays[k][:, 468:488]).all(axis=(1, 2)), \n",
    "                               ~np.isnan(numpy_arrays[k][:, 522:542]).all(axis=(1, 2)))\n",
    "    numpy_arrays[k] = numpy_arrays[k][frame_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad_edge(t, repeats, side):\n",
    "    if side == 'LEFT':\n",
    "        return tf.concat((tf.repeat(t[:1], repeats=repeats, axis=0), t), axis=0)\n",
    "    elif side == 'RIGHT':\n",
    "        return tf.concat((t, tf.repeat(t[-1:], repeats=repeats, axis=0)), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_sequence_tf(data, input_size):\n",
    "    # Get the sequence length (assuming it's the first dimension)\n",
    "    seq_len = tf.shape(data)[0]\n",
    "\n",
    "    # Remove frames where both hands have all NaN values\n",
    "    left_hand_mask = tf.reduce_all(tf.math.is_nan(data[:, 468:488]), axis=[1,2])\n",
    "    right_hand_mask = tf.reduce_all(tf.math.is_nan(data[:, 522:542]), axis=[1,2])\n",
    "    both_hands_nan_mask = tf.logical_and(left_hand_mask, right_hand_mask)\n",
    "    valid_frames_mask = tf.logical_not(both_hands_nan_mask)\n",
    "    data = tf.boolean_mask(data, valid_frames_mask, axis=0)\n",
    "\n",
    "    # Update the sequence length after removing NaN frames\n",
    "    seq_len = tf.shape(data)[0]\n",
    "\n",
    "    # Remove frames where mean of landmarks is 0\n",
    "    mean_landmarks_per_frame = tf.reduce_mean(data, axis=[1,2])\n",
    "    non_zero_mean_mask = tf.not_equal(mean_landmarks_per_frame, 0.0)\n",
    "    data = tf.boolean_mask(data, non_zero_mean_mask, axis=0)\n",
    "\n",
    "    # Update the sequence length after removing zero-mean frames\n",
    "    seq_len = tf.shape(data)[0]\n",
    "\n",
    "    if seq_len < input_size:\n",
    "        # If sequence is shorter than input_size, pad it with edge values\n",
    "        padding_size = input_size - seq_len\n",
    "        left_pad = padding_size // 2\n",
    "        right_pad = padding_size - left_pad\n",
    "        data = pad_edge(data, left_pad, 'LEFT')\n",
    "        data = pad_edge(data, right_pad, 'RIGHT')\n",
    "    elif seq_len > input_size:\n",
    "        # If sequence is longer than input_size, use mean pooling to downsample it\n",
    "        # If sequence length is less than square of input_size, repeat the frames\n",
    "        if seq_len < input_size ** 2:\n",
    "            repeats = input_size * input_size // seq_len\n",
    "            data = tf.repeat(data, repeats, axis=0)\n",
    "            seq_len = tf.shape(data)[0]  # update sequence length\n",
    "\n",
    "        # Pad to multiple of input_size\n",
    "        pad_size = -seq_len % input_size  # the amount to pad to make the length a multiple of input_size\n",
    "        pad_left = pad_size // 2\n",
    "        pad_right = pad_size - pad_left\n",
    "        data = pad_edge(data, pad_left, 'LEFT')\n",
    "        data = pad_edge(data, pad_right, 'RIGHT')\n",
    "\n",
    "        # Mean Pool\n",
    "        pool_size = tf.shape(data)[0] // input_size\n",
    "        data = tf.reshape(data, [input_size, pool_size] + data.shape[1:].as_list())\n",
    "        data = tf.reduce_mean(data, axis=1)\n",
    "\n",
    "    data = tf.where(tf.math.is_nan(data), 0.0, data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Set desired input size\n",
    "input_size = 100  # Replace with your desired input size\n",
    "\n",
    "# Adjust sequences\n",
    "# Assuming `tf_arrays` is a list of your data arrays in tf.Tensor format\n",
    "tf_arrays_adj = [adjust_sequence_tf(arr, input_size) for arr in numpy_arrays]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "543"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_arrays_adj[2][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('sign_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9168c8ad604fdf67bd4bb5dd46a506c73d5a2abac1af165cb0645ec69ec54d0f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
